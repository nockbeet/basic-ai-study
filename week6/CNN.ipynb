{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, Activation Function, Batch Norm 과제\n",
    "> 인공지능 스터디 다섯 번째 과제에 오신 것을 환영합니다! 강의를 들으면서 배운 다양한 지식들을 실습을 통해서 활용해볼 시간을 가질 것입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ymche\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ymche\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ymche\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch**는 PyTorch의 핵심 패키지로, 딥러닝 모델 구현에 필요한 기본 요소들을 포함하고있습니다.\n",
    "\n",
    "**torch.nn**은 신경망 모델 구현에 필요한 다양한 층(Layer)과 함수들을 포함\n",
    "\n",
    "**torchvision**은 Computer vision에서 사용하는 각종 테크닉들을 torch와 연동하여 구현한 라이브러리입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy**는 행렬 연산을 위한 기본 수치 계산 라이브러리\n",
    "\n",
    "**datetime**는 시간 기록용 라이브러리\n",
    "\n",
    "**os**, **sys**는 운영체제 관련 정보 접근을 위한 라이브러리\n",
    "\n",
    "**matplotlib**는 데이터 시각화 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow, imsave\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'CNN'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU가 있다면 GPU를 통해 학습을 가속화하고, 없으면 CPU로 학습하기 위해 device를 정해준다.\n",
    "\n",
    "**torch.cuda.is_avaliable()** 는 GPU가 사용가능한지를 판단하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple CNN Clssifier\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # (N, 1, 28, 28)\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 32, 14, 14)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 64, 7, 7)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7*7*64, 512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = self.conv(x) # (N, 64, 7, 7)\n",
    "        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n",
    "        y_ = self.fc(y_)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의를 위한 코드\n",
    "\n",
    "**nn.Module**: 뉴럴넷 구현을 위한 base class. forward, parameter 등 모델을 만들고 사용할 때 필요한 부분들이 내부적으로 구현되어 있음.\n",
    "\n",
    "**__init__**: python class의 constructor. 필요한 멤버변수들을 초기화하고, **nn.Sequential** or **nn.ModuleList**를 이용하여 모델의 구성을 정의한다.\n",
    "\n",
    "**forward**: 모델의 input을 받고 output을 return하는 함수.\n",
    "\n",
    "**nn.Conv2d**: Convolutional Layer. 입력 채널과 출력 채널을 parameter로 받는다. kernel size가 3이므로 padding 1을 통해 같은 크기가 나오도록 한다.\n",
    "\n",
    "**nn.MaxPool2d**: max pooling을 수행한다. feature map size를 줄여주는 역할.\n",
    "\n",
    "**nn.Dropout**: Dropout. p는 drop probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **사전지식**\n",
    "\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)의 주요 인자들:\n",
    "\n",
    "in_channels: 입력 채널 수\n",
    "out_channels: 출력 채널 수\n",
    "kernel_size: 컨볼루션 필터의 크기\n",
    "stride: 필터가 이동하는 간격\n",
    "padding: 입력 데이터 주변을 특정 값으로 채우는 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> 커널 사이즈 이해하기\n",
    "다음 상황에서 출력 feature map의 크기를 계산해보세요.\n",
    "\n",
    "입력 이미지 크기: 28x28\n",
    "\n",
    "커널 사이즈: 5x5\n",
    "\n",
    "stride: 1\n",
    "\n",
    "padding: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! <font color='green'><b>[ 정답 ]</b></font> 작성해주세요\n",
    "? 24x24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> ReLU의 역할\n",
    "ReLU의 역할을 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! <font color='green'><b>[ 정답 ]</b></font> 작성해주세요\n",
    "? 입력값(x)이 양수면 자기 자신(x)을 반환하고, 음수면 0을 반환하는 함수. 기존 sigmoid 함수에서 발생한 기울기 소실 문제를 해결하기 위한 대책으로 쓰이는 활성화 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> MaxPooling 계산\n",
    "\n",
    "MaxPool2d(2, 2)를 적용할 때, 다음 feature map의 크기 변화를 계산해보세요:\n",
    "입력 feature map: 14x14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! <font color='green'><b>[ 정답 ]</b></font> 작성해주세요\n",
    "? 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MyCNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정의한 모델을 메모리에 올리는 작업."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "### 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ <font color='red'><b>[ 생각해보기 ]</b></font> 정규화\n",
    "\n",
    "입력 정규화가 왜 필요할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hint : transforms.Normalize((0.1307,), (0.3081,))는 MNIST 데이터셋의 평균(mean)과 표준편차(standard deviation)를 사용한 정규화입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2995545.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST\\raw\\train-images-idx3-ubyte.gz to ../data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 166544.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1463435.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4521844.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(root='../data/', train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root='../data/', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**datasets**에는 여러 데이터들에 대해 다운로드하고 처리하는 클래스가 내장되어 있음. [참고](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "root 폴더에 없을 시에 download하고, 앞서 정의한 transform에 따라 전처리 된 데이터를 return함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=mnist_test, batch_size=100, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader**는 pytorch에서 학습 시에 데이터를 배치 사이즈만큼씩 효율적으로 불러오도록 돕는 클래스. 잘 사용할수록 GPU의 사용률이 올라간다.\n",
    "\n",
    "**shuffle**: every epochs 마다 데이터의 순서를 랜덤하게 섞는다.\n",
    "\n",
    "**drop_last**: 데이터의 개수가 배치 사이즈로 나눠떨어지지 않는 경우, 마지막 배치를 버린다. 주로 학습시에만 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 손실 함수 (내부적으로 softmax 포함)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nn.CrossEntropyLoss**: Cross entropy를 계산하는 Loss. softmax가 내부적으로 수행된다.\n",
    "\n",
    "**optim.Adam**: optim에는 여러 optimizer가 있고, Adam Optimizer는 대표적으로 많이 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최대 epoch 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "첫번째 for문 - 원하는 epoch만큼 반복\n",
    "\n",
    "두번째 for문 - training datset에서 배치 사이즈 만큼씩 모두 샘플링 될 때까지 반복.\n",
    "\n",
    "**Line 2**: MNIST dataset은 DataLoader를 통해 image와 label을 return.\n",
    "\n",
    "**Line 4**: 각각 Device에 올린다 (GPU or CPU)\n",
    "\n",
    "**Line 5**: 모델에 이미지를 넣고 forward propagation 한다.\n",
    "\n",
    "**Line 7**: 결과값 y_hat과 실제 정답 y에 대한 loss를 계산한다.\n",
    "\n",
    "**zero_grad (Line 9)**: 모델의 gradient를 0으로 초기화한다.\n",
    "\n",
    "**backward (Line 10)**: loss를 계산하는 것까지 연결되어있는 graph를 따라 gradient를 계산한다.\n",
    "\n",
    "**step (Line 11)**: 계산된 gradient를 모두 parameter에 적용한다.\n",
    "\n",
    "**eval (Line 17)**: 모델을 evaluation mode로 바꿔준다 (dropout 조정, Batch normalization 조정 등)\n",
    "\n",
    "**torch.no_grad (Line 19)**: 그래디언트 계산 비활성화\n",
    "\n",
    "**torch.max (Line 24)**: max value와 indices(즉, argmax)를 return.\n",
    "\n",
    "**train (Line 29)**: evaluation mode였던 모델을 train mode로 전환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5, Step: 0, Loss: 2.3281126022338867\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 2.7465667724609375, Accuracy: 16.8 %\n",
      "**********************************************\n",
      "Epoch: 0/5, Step: 500, Loss: 0.042913950979709625\n",
      "Epoch: 1/5, Step: 1000, Loss: 0.006804842036217451\n",
      "******************** Test ********************\n",
      "Step: 1000, Loss: 0.02018159069120884, Accuracy: 98.49 %\n",
      "**********************************************\n",
      "Epoch: 1/5, Step: 1500, Loss: 0.028603332117199898\n",
      "Epoch: 2/5, Step: 2000, Loss: 0.011636667884886265\n",
      "******************** Test ********************\n",
      "Step: 2000, Loss: 0.043180789798498154, Accuracy: 98.77 %\n",
      "**********************************************\n",
      "Epoch: 2/5, Step: 2500, Loss: 0.005013304762542248\n",
      "Epoch: 3/5, Step: 3000, Loss: 0.10214578360319138\n",
      "******************** Test ********************\n",
      "Step: 3000, Loss: 0.011012118309736252, Accuracy: 98.97 %\n",
      "**********************************************\n",
      "Epoch: 3/5, Step: 3500, Loss: 0.007053231820464134\n",
      "Epoch: 4/5, Step: 4000, Loss: 0.001892377738840878\n",
      "******************** Test ********************\n",
      "Step: 4000, Loss: 0.00973978266119957, Accuracy: 98.92999999999999 %\n",
      "**********************************************\n",
      "Epoch: 4/5, Step: 4500, Loss: 0.06030330806970596\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        # Training Discriminator\n",
    "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
    "        y_hat = model(x) # (N, 10)\n",
    "        \n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (images, labels) in enumerate(test_loader):\n",
    "                    x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
    "                    y_hat = model(x) # (N, 10)\n",
    "                    loss = criterion(y_hat, y)\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ <font color='red'><b>[ 퀴즈 ]</b></font> zero_grad()와 no_grad()의 차이\n",
    "\n",
    "optim.zero_grad()와 torch.no_grad()의 차이를 생각해보면서 이 코드에서는 어떤 주기로 평가되는지 서술하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! <font color='green'><b>[ 정답 ]</b></font> 작성해주세요\n",
    "\n",
    "? loss.backward()를 통해 gradient가 역전파로 계산되어 누적된다. optim.zero_grad()는 각 step마다 gradient를 0으로 초기화해줘서 이전 step의 gradient가 다음 step에 영향을 주지 않도록 한다. <br>\n",
    "한편 torch.no_grad()는 모델 평가 단계에서 gradient 계산을 비활성화하여 메모리 효율성을 높인다. <br>\n",
    "이 코드에선 `step % 1000 == 0` 조건에 따라 모델의 평가가 수행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Visualize\n",
    "\n",
    "학습시킨 모델이 얼만큼의 성능을 가지는지 테스트해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Step: 4685, Loss: 0.011253447271883488, Accuracy: 99.06 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(test_loader):\n",
    "        x, y = images.to(DEVICE), labels.to(DEVICE) # (N, 1, 28, 28), (N, )\n",
    "        y_hat = model(x) # (N, 10)\n",
    "        loss = criterion(y_hat, y)\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(mnist_test)*100))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7777번째 사진의 차원과, 정답값을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 7777 # 0 to 9999\n",
    "img, y = mnist_test[idx]\n",
    "img.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떻게 생겼는지도 궁금하군요. 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d395639d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = img.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unsqueeze**: 원하는 dim에 차원을 높여준다. 단일 이미지를 배치 형태로 변환 (N, C, H, W)해주는 과정으로 CNN forward를 위해서는 4D-Tensor여야합니다. 우리가 이제껏 봤던 RGB 이미지 데이터셋은 3차원이지만, 데이터의 개수를 고려해주는 N으로 한번 더 넓혔다고 생각해볼 수 있겠고요, 현재는 mnist gray scale dataset이므로 흑백차원이므로 C가 Grayscale: 1채널이라고 생각하면 될 것 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 학습시켰던 모델에 sample을 넣어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = img.to(DEVICE)\n",
    "out = model(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out값을 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -8.6256,  -3.8690, -10.0080,   8.8356,  -8.7642,  21.2227,  -2.7468,\n",
      "          -9.2686,   2.3063,   2.8462]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 무엇일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, idx = out.max(dim=-1)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 학습시켰던 가중치를 pkl로 저장하면서 마무리해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving params.\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음. 그런데 끝내기 전에 우리가 5주차에 배웠던 내용을 생각해보면 뭔가 언급이 안되었던 부분이 있었던 것 같은데요?\n",
    "정의된 MyCNN을 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple CNN Clssifier\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # (N, 1, 28, 28)\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 32, 14, 14)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 64, 7, 7)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7*7*64, 512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = self.conv(x) # (N, 64, 7, 7)\n",
    "        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n",
    "        y_ = self.fc(y_)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뭐가 빠졌죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음..\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "🤔\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "🤔\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "🤔\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "🤔\n",
    "\n",
    "아!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 맞습니다. BatchNorm이 없네요?\n",
    "이 CNN 모델에 BatchNorm이 포함되지 않은 것은 의도적인 선택으로 보이는데요, BatchNorm을 써야하는 상황은\n",
    "\n",
    "### 1. 깊은 신경망 구조\n",
    "\n",
    "레이어가 많은 심층 네트워크\n",
    "Internal Covariate Shift 문제 해결 필요\n",
    "\n",
    "\n",
    "### 2. 불안정한 학습 과정\n",
    "\n",
    "학습이 불안정하거나 수렴이 느린 경우\n",
    "그래디언트 소실/폭발 문제 발생 시\n",
    "\n",
    "\n",
    "### 3. 큰 배치 사이즈\n",
    "\n",
    "배치 사이즈가 충분히 클 때 효과적\n",
    "일반적으로 32 이상 권장\n",
    "\n",
    "\n",
    "### 4. 높은 학습률 필요\n",
    "\n",
    "빠른 학습을 위해 높은 learning rate 사용 시\n",
    "학습 안정성 확보 필요\n",
    "\n",
    "으로 정리할 수 있을 것 같습니다. \n",
    "\n",
    "이 MNIST 예제의 경우 간단한 구조와 데이터셋 특성상 BatchNorm 없이도 충분히 학습 가능합니다.\n",
    "\n",
    "하지만 코드를 안보고 넘어가면 아쉬우니까 다음 코드에다 BatchNorm을 추가해서 수정해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple CNN Clssifier\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # (N, 1, 28, 28)\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 32, 14, 14)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # (N, 64, 7, 7)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7*7*64, 512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = self.conv(x) # (N, 64, 7, 7)\n",
    "        y_ = y_.view(y_.size(0), -1) # (N, 64*7*7)\n",
    "        y_ = self.fc(y_)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번주에 Low-Rank Adaptation (LoRA)도 학습해봤는데요, 관심있으신 분들은 난이도에 맞게 아래 자료도 읽어보시면 좋을 것 같아요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음.. 난 아직 논문까지는 어려워.. 😕😕\n",
    "**Easy Mode** : 논문 리뷰 읽기 [https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/lora/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한번 읽어볼까? 얼마나 어렵겠어? 😎😎\n",
    "\n",
    "Hard Mode : 논문 원본 읽기 [https://arxiv.org/abs/2106.09685]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎉🎉🎉 5주차 과제 완료! 🎉🎉🎉\n",
    "```python\n",
    "🐙\n",
    "여러분 모두 수고 했어요!! 이번주 과제를 complete한 당신에게 행운을 드립니다. \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
